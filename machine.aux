\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{pythonmachinelearning}
\citation{cam}
\citation{VanPoucke2016}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction and Background}{2}{section.1}}
\newlabel{sec:intro}{{1}{2}{Introduction and Background}{section.1}{}}
\citation{seerwebsite}
\citation{cam}
\citation{ISI:000337467400005}
\citation{ISI:000355882700012}
\citation{Gordon19851065}
\citation{Bou-Hamad201144}
\citation{Ishwaran20101056}
\citation{seerdoc}
\citation{bowles}
\citation{downey}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data acquisition}{5}{section.2}}
\newlabel{sec:dataacquition}{{2}{5}{Data acquisition}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data preparation and preprocessing}{5}{subsection.2.1}}
\newlabel{subsec:dataprep}{{2.1}{5}{Data preparation and preprocessing}{subsection.2.1}{}}
\citation{bowles}
\citation{census}
\citation{geocode}
\citation{elevation}
\citation{supp}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Encoding of gender in the SEER incidence files. These types of categorical variables need to be transformed via one-hot-encoding.}}{6}{table.1}}
\newlabel{tab:sex}{{1}{6}{Encoding of gender in the SEER incidence files. These types of categorical variables need to be transformed via one-hot-encoding}{table.1}{}}
\newlabel{eqn:onehotmale}{{2.1}{6}{Data preparation and preprocessing}{equation.2.1}{}}
\newlabel{eqn:onehotfemale}{{2.2}{6}{Data preparation and preprocessing}{equation.2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Example of the transformation of \color@box {}{white}{\texttt  {STATE-COUNTY RECODE}} to \color@box {}{white}{\texttt  {elevation}}, \color@box {}{white}{\texttt  {lat}}, and \color@box {}{white}{\texttt  {lng}}.}}{7}{table.2}}
\newlabel{tab:nmhead}{{2}{7}{Example of the transformation of \codewhite {STATE-COUNTY RECODE} to \codewhite {elevation}, \codewhite {lat}, and \codewhite {lng}}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  Filters applied to the Colon Cancer data.}}{8}{table.3}}
\newlabel{tab:colonfilter}{{3}{8}{Filters applied to the Colon Cancer data}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  Filters applied to the Lung Cancer data.}}{8}{table.4}}
\newlabel{tab:lungfilter}{{4}{8}{Filters applied to the Lung Cancer data}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Traditional Survival Analysis}{8}{subsection.2.2}}
\citation{cam}
\citation{Kaplan1958457}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces  Filters applied to the Breast Cancer data.}}{9}{table.5}}
\newlabel{tab:breastfilter}{{5}{9}{Filters applied to the Breast Cancer data}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces  Example data to illustate traditional Survival Analsyis.}}{10}{table.6}}
\newlabel{tab:censoredexample}{{6}{10}{Example data to illustate traditional Survival Analsyis}{table.6}{}}
\citation{kuhn}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces  Kaplan-Meier table corresponding to the example data in Table\nobreakspace  {}(\ref  {tab:censoredexample}).}}{11}{table.7}}
\newlabel{tab:kaplanexample}{{7}{11}{Kaplan-Meier table corresponding to the example data in Table~(\ref {tab:censoredexample})}{table.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Traditional Kaplan-Meier estimate of the survival curve for all colon cancer patients. Fitted with 113072 observations, 71804 censored.}}{11}{figure.1}}
\newlabel{fig:colonkaplan}{{1}{11}{Traditional Kaplan-Meier estimate of the survival curve for all colon cancer patients. Fitted with 113072 observations, 71804 censored}{figure.1}{}}
\newlabel{subsec:survprimer}{{2.2}{11}{Traditional Survival Analysis}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Traditional Kaplan-Meier estimate of the survival curve for all breast cancer patients. Fitted with 329949 observatins, 292279 censored.}}{12}{figure.2}}
\newlabel{fig:breastkaplan}{{2}{12}{Traditional Kaplan-Meier estimate of the survival curve for all breast cancer patients. Fitted with 329949 observatins, 292279 censored}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Transformation of Censored Data for Machine Learning}{12}{section.3}}
\newlabel{subsec:transformation}{{3}{12}{Transformation of Censored Data for Machine Learning}{section.3}{}}
\newlabel{eq:kaplanmeier}{{3.1}{12}{Transformation of Censored Data for Machine Learning}{equation.3.1}{}}
\newlabel{eq:hhazard}{{3.2}{12}{Transformation of Censored Data for Machine Learning}{equation.3.2}{}}
\citation{amstat}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Traditional Kaplan-Meier estimate of the survival curve for all lung cancer patients. Fitted with 177089 observatins, 47409 censored.}}{13}{figure.3}}
\newlabel{fig:lungkaplan}{{3}{13}{Traditional Kaplan-Meier estimate of the survival curve for all lung cancer patients. Fitted with 177089 observatins, 47409 censored}{figure.3}{}}
\newlabel{eq:hazardtosurvival}{{3.6}{13}{Transformation of Censored Data for Machine Learning}{equation.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces  Example of four columns in an uncensored record in the untransformed dataset.}}{14}{table.8}}
\newlabel{tab:originaldead}{{8}{14}{Example of four columns in an uncensored record in the untransformed dataset}{table.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces  Example of four columns in a censored record in the untransformed dataset.}}{14}{table.9}}
\newlabel{tab:originalalive}{{9}{14}{Example of four columns in a censored record in the untransformed dataset}{table.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces  Example of four columns in an uncensored record in the transformed dataset.}}{14}{table.10}}
\newlabel{tab:transformeddead}{{10}{14}{Example of four columns in an uncensored record in the transformed dataset}{table.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces  Example of four columns in a censored record in the transformed dataset.}}{15}{table.11}}
\newlabel{tab:transformedalive}{{11}{15}{Example of four columns in a censored record in the transformed dataset}{table.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Training and Test Partitions}{15}{section.4}}
\newlabel{subsec:traintest}{{4}{15}{Training and Test Partitions}{section.4}{}}
\citation{wisdom}
\citation{cassidy}
\citation{outliers}
\@writefile{toc}{\contentsline {section}{\numberline {5}Prediction Models}{16}{section.5}}
\newlabel{sec:predmodels}{{5}{16}{Prediction Models}{section.5}{}}
\citation{supp}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Decision Trees and Random Forests}{17}{subsection.5.1}}
\citation{rf}
\citation{kagglerf}
\citation{deeplearning}
\citation{toxicity}
\citation{keras}
\citation{deeplearning}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Illustration of ensemble methods showing how a collection of base learners with poor accuracy can combine to produce an accurate ensemble learner.}}{18}{figure.4}}
\newlabel{fig:ensemble}{{4}{18}{Illustration of ensemble methods showing how a collection of base learners with poor accuracy can combine to produce an accurate ensemble learner}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Multi-Layer Perceptron Neural Networks}{18}{subsection.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{19}{section.6}}
\newlabel{sec:results}{{6}{19}{Results}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Example of the construction of the binary classifiers for 6, 12, and 60 months survival. A subjects hazard curve $\lambda (\mathbf  {X}, t)$ is predicted by the model for times out to 120 months. The survival curve is then readily computed as in Equation\nobreakspace  {}(\ref  {eq:hazardtosurvival}). For this example, the 6-month and 12-month classifiers predict survival, while the 60-month classifier predicts expiry.}}{19}{figure.6}}
\newlabel{fig:survivalexample}{{6}{19}{Example of the construction of the binary classifiers for 6, 12, and 60 months survival. A subjects hazard curve $\lambda (\mathbf {X}, t)$ is predicted by the model for times out to 120 months. The survival curve is then readily computed as in Equation~(\ref {eq:hazardtosurvival}). For this example, the 6-month and 12-month classifiers predict survival, while the 60-month classifier predicts expiry}{figure.6}{}}
\citation{supp}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces  AUC values for the Random Forest and Neural Networks model binary classifiers derived from the full survival curve predictions; see text for details. The number of subjects that were used in the calculation of a given AUC score are given in parenthesis after the score. }}{20}{table.12}}
\newlabel{tab:AUC}{{12}{20}{AUC values for the Random Forest and Neural Networks model binary classifiers derived from the full survival curve predictions; see text for details. The number of subjects that were used in the calculation of a given AUC score are given in parenthesis after the score}{table.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Performance Metrics}{20}{subsection.6.1}}
\newlabel{sec:performancemetrics}{{6.1}{20}{Performance Metrics}{subsection.6.1}{}}
\citation{supp}
\citation{flask}
\citation{heroku}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces  Percentage agreement for the Random Forest and Neural Network classifiers for 6, 12, and 60 month survival predictions on the test data for each cancer type.}}{21}{table.13}}
\newlabel{tab:agree}{{13}{21}{Percentage agreement for the Random Forest and Neural Network classifiers for 6, 12, and 60 month survival predictions on the test data for each cancer type}{table.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Model Agreement}{21}{subsection.6.2}}
\newlabel{subsec:agreement}{{6.2}{21}{Model Agreement}{subsection.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Survival Curve Prediction Apps}{21}{section.7}}
\newlabel{sec:apps}{{7}{21}{Survival Curve Prediction Apps}{section.7}{}}
\citation{kob4}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Example input data to the Colon Cancer neural network app \url  {http://coloncancernn.herokuapp.com/}.}}{22}{table.14}}
\newlabel{tab:boston1940}{{14}{22}{Example input data to the Colon Cancer neural network app \url {http://coloncancernn.herokuapp.com/}}{table.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Example input data to the Lung Cancer random forest app \url  {http://lung-cancer.herokuapp.com/}.}}{23}{table.15}}
\newlabel{tab:lungmaritalstatus}{{15}{23}{Example input data to the Lung Cancer random forest app \url {http://lung-cancer.herokuapp.com/}}{table.15}{}}
\citation{umass}
\citation{supp}
\@writefile{toc}{\contentsline {section}{\numberline {8}Further Directions}{24}{section.8}}
\newlabel{sec:furtherdirections}{{8}{24}{Further Directions}{section.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Selected Features}{25}{appendix.A}}
\newlabel{sec:features}{{A}{25}{Selected Features}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Colon Cancer Feature Selection}{25}{subsection.A.1}}
\newlabel{subsec:colonfeatures}{{A.1}{25}{Colon Cancer Feature Selection}{subsection.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Lung Cancer Feature Selection}{27}{subsection.A.2}}
\newlabel{subsec:lungfeatures}{{A.2}{27}{Lung Cancer Feature Selection}{subsection.A.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Breast Cancer Feature Selection}{30}{subsection.A.3}}
\newlabel{subsec:breastfeatures}{{A.3}{30}{Breast Cancer Feature Selection}{subsection.A.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Pseudocode for the Data Transformation}{32}{appendix.B}}
\newlabel{subsec:pseudocode}{{B}{32}{Pseudocode for the Data Transformation}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Model Architecture and Python Code}{33}{appendix.C}}
\newlabel{sec:architecture}{{C}{33}{Model Architecture and Python Code}{appendix.C}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Breast Random Forest Model}{33}{subsection.C.1}}
\newlabel{subsec:breastrf}{{C.1}{33}{Breast Random Forest Model}{subsection.C.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Colon Random Forest Model}{33}{subsection.C.2}}
\newlabel{subsec:colonrf}{{C.2}{33}{Colon Random Forest Model}{subsection.C.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Lung Random Forest Model}{33}{subsection.C.3}}
\newlabel{subsec:lungrf}{{C.3}{33}{Lung Random Forest Model}{subsection.C.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Breast Neural Network Model}{33}{subsection.C.4}}
\newlabel{subsec:breastnn}{{C.4}{33}{Breast Neural Network Model}{subsection.C.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.5}Colon Cancer Neural Network Model}{34}{subsection.C.5}}
\newlabel{subsec:colonnn}{{C.5}{34}{Colon Cancer Neural Network Model}{subsection.C.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.6}Lung Cancer Neural Network Model}{34}{subsection.C.6}}
\newlabel{subsec:lungnn}{{C.6}{34}{Lung Cancer Neural Network Model}{subsection.C.6}{}}
\bibstyle{ieeetr}
\bibdata{machinebib}
\bibcite{pythonmachinelearning}{{1}{}{{}}{{}}}
\bibcite{cam}{{2}{}{{}}{{}}}
\bibcite{VanPoucke2016}{{3}{}{{}}{{}}}
\bibcite{seerwebsite}{{4}{}{{}}{{}}}
\bibcite{ISI:000337467400005}{{5}{}{{}}{{}}}
\@writefile{toc}{\contentsline {paragraph}{Note added.}{35}{section*.3}}
\bibcite{ISI:000355882700012}{{6}{}{{}}{{}}}
\bibcite{Gordon19851065}{{7}{}{{}}{{}}}
\bibcite{Bou-Hamad201144}{{8}{}{{}}{{}}}
\bibcite{Ishwaran20101056}{{9}{}{{}}{{}}}
\bibcite{seerdoc}{{10}{}{{}}{{}}}
\bibcite{bowles}{{11}{}{{}}{{}}}
\bibcite{downey}{{12}{}{{}}{{}}}
\bibcite{census}{{13}{}{{}}{{}}}
\bibcite{geocode}{{14}{}{{}}{{}}}
\bibcite{elevation}{{15}{}{{}}{{}}}
\bibcite{supp}{{16}{}{{}}{{}}}
\bibcite{Kaplan1958457}{{17}{}{{}}{{}}}
\bibcite{kuhn}{{18}{}{{}}{{}}}
\bibcite{amstat}{{19}{}{{}}{{}}}
\bibcite{wisdom}{{20}{}{{}}{{}}}
\bibcite{cassidy}{{21}{}{{}}{{}}}
\bibcite{outliers}{{22}{}{{}}{{}}}
\bibcite{rf}{{23}{}{{}}{{}}}
\bibcite{kagglerf}{{24}{}{{}}{{}}}
\bibcite{deeplearning}{{25}{}{{}}{{}}}
\bibcite{toxicity}{{26}{}{{}}{{}}}
\bibcite{keras}{{27}{}{{}}{{}}}
\bibcite{flask}{{28}{}{{}}{{}}}
\bibcite{heroku}{{29}{}{{}}{{}}}
\bibcite{kob4}{{30}{}{{}}{{}}}
\bibcite{umass}{{31}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{RF1}{38}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  The top levels of a decision tree trained on the Lung Cancer training data.}}{38}{figure.5}}
\newlabel{fig:lungdt}{{5}{38}{The top levels of a decision tree trained on the Lung Cancer training data}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Box plots showing the distributions of the signed difference between the MLP model's prediction for the probability of surviving 6 months and the Random Forest model's prediction of the same quantity for breast cancer. The plot shows the same quantity for the 12 and 60 months classifiers. It is apparent from the figures that the outliers are due to the neural network models predicting higher survival probablitlies than the random forest for some few cases. These differences were evaluated for the 3300 test patients in the breast cancer data.}}{39}{figure.7}}
\newlabel{fig:breastbox}{{7}{39}{Box plots showing the distributions of the signed difference between the MLP model's prediction for the probability of surviving 6 months and the Random Forest model's prediction of the same quantity for breast cancer. The plot shows the same quantity for the 12 and 60 months classifiers. It is apparent from the figures that the outliers are due to the neural network models predicting higher survival probablitlies than the random forest for some few cases. These differences were evaluated for the 3300 test patients in the breast cancer data}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  Box plots showing the distributions of the signed difference between the MLP model's prediction for the probability of surviving 6 months and the Random Forest model's prediction of the same quantity for colon cancer. The plot shows the same quantity for the 12 and 60 months classifiers. It is apparent from the figures that the outliers are due to the neural network models predicting higher survival probablitlies than the random forest for some few cases. These differences were evaluated for the 5654 test patients in the colon cancer data.}}{40}{figure.8}}
\newlabel{fig:colonbox}{{8}{40}{Box plots showing the distributions of the signed difference between the MLP model's prediction for the probability of surviving 6 months and the Random Forest model's prediction of the same quantity for colon cancer. The plot shows the same quantity for the 12 and 60 months classifiers. It is apparent from the figures that the outliers are due to the neural network models predicting higher survival probablitlies than the random forest for some few cases. These differences were evaluated for the 5654 test patients in the colon cancer data}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Box plots showing the distributions of the signed difference between the MLP model's prediction for the probability of surviving 6 months and the Random Forest model's prediction of the same quantity for lung cancer. The plot shows the same quantity for the 12 and 60 months classifiers. These differences were evaluated for the 5313 test patients in the lung cancer data. The Interquartile Ranges for lung cancer are visibly larger than those for breast cancer and colon cancer shown in fig\nobreakspace  {}\ref  {fig:breastbox} and fig\nobreakspace  {}\ref  {fig:colonbox}.}}{41}{figure.9}}
\newlabel{fig:lungbox}{{9}{41}{Box plots showing the distributions of the signed difference between the MLP model's prediction for the probability of surviving 6 months and the Random Forest model's prediction of the same quantity for lung cancer. The plot shows the same quantity for the 12 and 60 months classifiers. These differences were evaluated for the 5313 test patients in the lung cancer data. The Interquartile Ranges for lung cancer are visibly larger than those for breast cancer and colon cancer shown in fig~\ref {fig:breastbox} and fig~\ref {fig:colonbox}}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  Colon Cancer Survival Curve predicted from the data in Table\nobreakspace  {}(\ref  {tab:boston1940}) using the neural network web app \url  {http://coloncancer.herokuapp.com/}.}}{42}{figure.10}}
\newlabel{fig:boston1940}{{10}{42}{Colon Cancer Survival Curve predicted from the data in Table~(\ref {tab:boston1940}) using the neural network web app \url {http://coloncancer.herokuapp.com/}}{figure.10}{}}
